{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLaMA Task Agent - Live Demo on Kaggle\n",
    "\n",
    "**Quick Test**: Run the trained model with FastAPI\n",
    "\n",
    "**Setup**: \n",
    "1. Enable GPU: Settings → Accelerator → GPU T4 x2\n",
    "2. Add Data: + Add Data → Upload `models/lora-adapter` folder as dataset\n",
    "3. Run all cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:06:04.670897Z",
     "iopub.status.busy": "2026-01-28T20:06:04.670099Z",
     "iopub.status.idle": "2026-01-28T20:06:08.072087Z",
     "shell.execute_reply": "2026-01-28T20:06:08.071368Z",
     "shell.execute_reply.started": "2026-01-28T20:06:04.670870Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers peft bitsandbytes accelerate fastapi uvicorn pydantic huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Model Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:06:29.394778Z",
     "iopub.status.busy": "2026-01-28T20:06:29.394466Z",
     "iopub.status.idle": "2026-01-28T20:06:29.698688Z",
     "shell.execute_reply": "2026-01-28T20:06:29.697699Z",
     "shell.execute_reply.started": "2026-01-28T20:06:29.394746Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapter copied from dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Copy adapter from Kaggle dataset to working directory\n",
    "!mkdir -p models/lora-adapter\n",
    "\n",
    "# If you uploaded as dataset, copy from /kaggle/input/\n",
    "# Update path based on your dataset name\n",
    "dataset_path = '/kaggle/input/taskai'  # Adjust if needed\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    !cp -r {dataset_path}/* models/lora-adapter/\n",
    "    print(\"Adapter copied from dataset\")\n",
    "else:\n",
    "    print(\"Dataset not found. Upload models/lora-adapter folder as Kaggle dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Agent Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:06:33.038941Z",
     "iopub.status.busy": "2026-01-28T20:06:33.038183Z",
     "iopub.status.idle": "2026-01-28T20:06:33.153010Z",
     "shell.execute_reply": "2026-01-28T20:06:33.152312Z",
     "shell.execute_reply.started": "2026-01-28T20:06:33.038907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create directories\n",
    "!mkdir -p agent configs serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:06:35.539406Z",
     "iopub.status.busy": "2026-01-28T20:06:35.538606Z",
     "iopub.status.idle": "2026-01-28T20:06:35.544815Z",
     "shell.execute_reply": "2026-01-28T20:06:35.544047Z",
     "shell.execute_reply.started": "2026-01-28T20:06:35.539373Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting agent/tools.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile agent/tools.py\n",
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "\n",
    "tasks = []\n",
    "\n",
    "def add_task(title: str, due_date: str) -> Dict:\n",
    "    task = {\n",
    "        \"id\": len(tasks) + 1,\n",
    "        \"title\": title,\n",
    "        \"due_date\": due_date,\n",
    "        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"completed\": False\n",
    "    }\n",
    "    tasks.append(task)\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"message\": f\"Task added: '{title}' due on {due_date}\",\n",
    "        \"task_count\": len(tasks)\n",
    "    }\n",
    "\n",
    "def list_tasks() -> Dict:\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"tasks\": tasks,\n",
    "        \"count\": len(tasks)\n",
    "    }\n",
    "\n",
    "def summarize_tasks() -> Dict:\n",
    "    total = len(tasks)\n",
    "    completed = sum(1 for t in tasks if t[\"completed\"])\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"summary\": f\"You have {total} tasks ({completed} completed, {total - completed} pending)\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:06:47.855807Z",
     "iopub.status.busy": "2026-01-28T20:06:47.855200Z",
     "iopub.status.idle": "2026-01-28T20:06:47.860710Z",
     "shell.execute_reply": "2026-01-28T20:06:47.859988Z",
     "shell.execute_reply.started": "2026-01-28T20:06:47.855782Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting agent/executor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile agent/executor.py\n",
    "import re\n",
    "from agent.tools import add_task, list_tasks, summarize_tasks\n",
    "\n",
    "def parse_response(text: str) -> dict:\n",
    "    analysis_match = re.search(r'<analysis>(.*?)</analysis>', text, re.DOTALL)\n",
    "    action_match = re.search(r'<action>(.*?)</action>', text, re.DOTALL)\n",
    "    final_match = re.search(r'<final>(.*?)</final>', text, re.DOTALL)\n",
    "    \n",
    "    return {\n",
    "        \"analysis\": analysis_match.group(1).strip() if analysis_match else None,\n",
    "        \"action\": action_match.group(1).strip() if action_match else None,\n",
    "        \"final\": final_match.group(1).strip() if final_match else None\n",
    "    }\n",
    "\n",
    "def execute_action(action_str: str) -> dict:\n",
    "    if not action_str:\n",
    "        return {\"error\": \"No action to execute\"}\n",
    "    \n",
    "    if \"add_task\" in action_str:\n",
    "        title_match = re.search(r'title=\"([^\"]+)\"', action_str)\n",
    "        date_match = re.search(r'due_date=\"([^\"]+)\"', action_str)\n",
    "        if title_match and date_match:\n",
    "            return add_task(title_match.group(1), date_match.group(1))\n",
    "    elif \"list_tasks\" in action_str:\n",
    "        return list_tasks()\n",
    "    elif \"summarize_tasks\" in action_str:\n",
    "        return summarize_tasks()\n",
    "    \n",
    "    return {\"error\": \"Unknown action\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:06:54.465471Z",
     "iopub.status.busy": "2026-01-28T20:06:54.464708Z",
     "iopub.status.idle": "2026-01-28T20:06:54.576046Z",
     "shell.execute_reply": "2026-01-28T20:06:54.575443Z",
     "shell.execute_reply.started": "2026-01-28T20:06:54.465441Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "\n",
    "print(\"Token loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:06:56.991653Z",
     "iopub.status.busy": "2026-01-28T20:06:56.991049Z",
     "iopub.status.idle": "2026-01-28T20:06:57.704651Z",
     "shell.execute_reply": "2026-01-28T20:06:57.703998Z",
     "shell.execute_reply.started": "2026-01-28T20:06:56.991626Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in to Hugging Face\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=hf_token)\n",
    "print(\"Logged in to Hugging Face\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:07:01.521062Z",
     "iopub.status.busy": "2026-01-28T20:07:01.520751Z",
     "iopub.status.idle": "2026-01-28T20:07:01.584030Z",
     "shell.execute_reply": "2026-01-28T20:07:01.583359Z",
     "shell.execute_reply.started": "2026-01-28T20:07:01.521033Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'user', 'id': '67d9cbbb7a087207dfdaa2cd', 'name': 'altruvi', 'fullname': 'Aswani Sahoo', 'email': 'aswanisahoo227@gmail.com', 'emailVerified': True, 'canPay': False, 'billingMode': 'prepaid', 'periodEnd': 1769904000, 'isPro': False, 'avatarUrl': '/avatars/6637de6fb2c275008f01f7b64de54319.svg', 'orgs': [], 'auth': {'type': 'access_token', 'accessToken': {'displayName': 'taskai', 'role': 'read', 'createdAt': '2026-01-28T20:05:37.852Z'}}}\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import whoami\n",
    "\n",
    "print(whoami())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Models (Base + Fine-Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:07:35.824595Z",
     "iopub.status.busy": "2026-01-28T20:07:35.824031Z",
     "iopub.status.idle": "2026-01-28T20:10:56.062676Z",
     "shell.execute_reply": "2026-01-28T20:10:56.061869Z",
     "shell.execute_reply.started": "2026-01-28T20:07:35.824567Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 20:07:52.148898: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769630872.409594      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1769630872.489284      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1769630873.099487      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769630873.099557      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769630873.099560      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769630873.099563      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ba41ef3e0449a3ba353652a365c4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135dc0c373134ee1b25f8a9ba285890b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e21384c383408ca770d7949667687e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model: meta-llama/Llama-3.1-8B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62c20cbd2d14a24b0392233103268e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bdcc010ab746acbfae7f295c91d0fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38196266786b4ea191ac9b5162e6cc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482848038cd549f2aaad6cd5d08f3697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf63622df2b460c96892890e0566b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105def4b641d4d13890813aeccb70c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b6ba623343408e993a79b93cfecd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800845d20e3e498883554787abc4c501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afe4f666c3a4edbb69f817aa2133948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LoRA adapter from models/lora-adapter\n",
      "Both models loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "print(\"Loading models...\")\n",
    "\n",
    "# 4-bit quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "adapter_path = \"models/lora-adapter\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load base model\n",
    "print(f\"Loading base model: {model_name}\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Load fine-tuned model\n",
    "print(f\"Loading LoRA adapter from {adapter_path}\")\n",
    "finetuned_model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "\n",
    "print(\"Both models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  COMPARISON: Base vs Fine-Tuned\n",
    "\n",
    "**This is the proof that fine-tuning works!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:15:55.033293Z",
     "iopub.status.busy": "2026-01-28T20:15:55.032455Z",
     "iopub.status.idle": "2026-01-28T20:15:55.038991Z",
     "shell.execute_reply": "2026-01-28T20:15:55.038198Z",
     "shell.execute_reply.started": "2026-01-28T20:15:55.033261Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_response(model, query: str, max_tokens=200):\n",
    "    \"\"\"Generate response from model\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a task assistant. Use <analysis> and <action> for tools, <final> for conversation.\"},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:17:19.897004Z",
     "iopub.status.busy": "2026-01-28T20:17:19.896242Z",
     "iopub.status.idle": "2026-01-28T20:17:29.968130Z",
     "shell.execute_reply": "2026-01-28T20:17:29.967408Z",
     "shell.execute_reply.started": "2026-01-28T20:17:19.896975Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                    BASE MODEL (Prompt-Only)\n",
      "======================================================================\n",
      "<analysis>\n",
      "User wants to create a new task 'buy groceries' due date tomorrow.\n",
      "</analysis>\n",
      "\n",
      "<action>\n",
      "add_task(title=\"Buy groceries\", due_date=\"2026-01-26\")\n",
      "</action>\n",
      "\n",
      "======================================================================\n",
      "                  FINE-TUNED MODEL (LoRA)\n",
      "======================================================================\n",
      "<analysis>\n",
      "User wants to create a new task 'buy groceries' due date tomorrow.\n",
      "</analysis>\n",
      "\n",
      "<action>\n",
      "add_task(title=\"Buy groceries\", due_date=\"2026-01-26\")\n",
      "</action>\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ANALYSIS:\n",
      "Base Model - Has <action> tag: True\n",
      "Fine-Tuned - Has <action> tag: True\n",
      "\n",
      "Notice: Fine-tuned model consistently uses the correct format!\n"
     ]
    }
   ],
   "source": [
    "test_query = \"Add a task to buy groceries tomorrow\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"                    BASE MODEL (Prompt-Only)\")\n",
    "print(\"=\"*70)\n",
    "base_response = generate_response(base_model, test_query)\n",
    "print(base_response)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"                  FINE-TUNED MODEL (LoRA)\")\n",
    "print(\"=\"*70)\n",
    "finetuned_response = generate_response(finetuned_model, test_query)\n",
    "print(finetuned_response)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Check format compliance\n",
    "from agent.executor import parse_response\n",
    "\n",
    "base_parsed = parse_response(base_response)\n",
    "ft_parsed = parse_response(finetuned_response)\n",
    "\n",
    "print(\"\\nANALYSIS:\")\n",
    "print(f\"Base Model - Has <action> tag: {base_parsed['action'] is not None}\")\n",
    "print(f\"Fine-Tuned - Has <action> tag: {ft_parsed['action'] is not None}\")\n",
    "print(\"\\nNotice: Fine-tuned model consistently uses the correct format!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:18:44.405326Z",
     "iopub.status.busy": "2026-01-28T20:18:44.404621Z",
     "iopub.status.idle": "2026-01-28T20:18:44.410169Z",
     "shell.execute_reply": "2026-01-28T20:18:44.409491Z",
     "shell.execute_reply.started": "2026-01-28T20:18:44.405294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from agent.executor import parse_response, execute_action\n",
    "\n",
    "def test_query(query: str):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"USER: {query}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    response = generate_response(finetuned_model, query)\n",
    "    print(f\"\\nAGENT RESPONSE:\\n{response}\")\n",
    "    \n",
    "    # Parse and execute\n",
    "    parsed = parse_response(response)\n",
    "    \n",
    "    if parsed['action']:\n",
    "        result = execute_action(parsed['action'])\n",
    "        print(f\"\\nEXECUTION RESULT:\\n{result}\")\n",
    "    elif parsed['final']:\n",
    "        print(f\"\\nDIRECT RESPONSE: {parsed['final']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:19:07.855749Z",
     "iopub.status.busy": "2026-01-28T20:19:07.855179Z",
     "iopub.status.idle": "2026-01-28T20:19:12.698728Z",
     "shell.execute_reply": "2026-01-28T20:19:12.698064Z",
     "shell.execute_reply.started": "2026-01-28T20:19:07.855721Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "USER: Add a task to buy groceries tomorrow\n",
      "============================================================\n",
      "\n",
      "AGENT RESPONSE:\n",
      "<analysis>\n",
      "User wants to create a new task 'buy groceries' with due date 'tomorrow'.\n",
      "</analysis>\n",
      "\n",
      "<action>\n",
      "add_task(title=\"Buy groceries\", due_date=\"tomorrow\")\n",
      "</action>\n",
      "\n",
      "EXECUTION RESULT:\n",
      "{'status': 'success', 'message': \"Task added: 'Buy groceries' due on tomorrow\", 'task_count': 1}\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Add task\n",
    "test_query(\"Add a task to buy groceries tomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:19:17.639603Z",
     "iopub.status.busy": "2026-01-28T20:19:17.638885Z",
     "iopub.status.idle": "2026-01-28T20:19:22.100007Z",
     "shell.execute_reply": "2026-01-28T20:19:22.099376Z",
     "shell.execute_reply.started": "2026-01-28T20:19:17.639572Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "USER: Remind me to call the dentist on Friday\n",
      "============================================================\n",
      "\n",
      "AGENT RESPONSE:\n",
      "<analysis>\n",
      "User wants a reminder to call the dentist on Friday.\n",
      "</analysis>\n",
      "\n",
      "<action>\n",
      "reminder.add(user=\"Me\", task=\"Call dentist\", due_date=\"Friday\")\n",
      "</action>\n",
      "\n",
      "EXECUTION RESULT:\n",
      "{'error': 'Unknown action'}\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Add another task\n",
    "test_query(\"Remind me to call the dentist on Friday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:19:25.106647Z",
     "iopub.status.busy": "2026-01-28T20:19:25.105980Z",
     "iopub.status.idle": "2026-01-28T20:19:27.983549Z",
     "shell.execute_reply": "2026-01-28T20:19:27.982785Z",
     "shell.execute_reply.started": "2026-01-28T20:19:25.106616Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "USER: What tasks do I have?\n",
      "============================================================\n",
      "\n",
      "AGENT RESPONSE:\n",
      "<analysis>\n",
      "User is requesting a list of all tasks.\n",
      "</analysis>\n",
      "\n",
      "<action>\n",
      "list_tasks()\n",
      "</action>\n",
      "\n",
      "EXECUTION RESULT:\n",
      "{'status': 'success', 'tasks': [{'id': 1, 'title': 'Buy groceries', 'due_date': 'tomorrow', 'created_at': '2026-01-28 20:19:12', 'completed': False}], 'count': 1}\n"
     ]
    }
   ],
   "source": [
    "# Test 3: List tasks\n",
    "test_query(\"What tasks do I have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:19:30.328463Z",
     "iopub.status.busy": "2026-01-28T20:19:30.327675Z",
     "iopub.status.idle": "2026-01-28T20:19:33.287094Z",
     "shell.execute_reply": "2026-01-28T20:19:33.286366Z",
     "shell.execute_reply.started": "2026-01-28T20:19:30.328430Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "USER: Summarize my tasks\n",
      "============================================================\n",
      "\n",
      "AGENT RESPONSE:\n",
      "<analysis>\n",
      "User wants a summary of their tasks.\n",
      "</analysis>\n",
      "\n",
      "<action>\n",
      "summarize_tasks()\n",
      "</action>\n",
      "\n",
      "EXECUTION RESULT:\n",
      "{'status': 'success', 'summary': 'You have 1 tasks (0 completed, 1 pending)'}\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Summarize\n",
    "test_query(\"Summarize my tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:21:54.541183Z",
     "iopub.status.busy": "2026-01-28T20:21:54.540515Z",
     "iopub.status.idle": "2026-01-28T20:21:57.635326Z",
     "shell.execute_reply": "2026-01-28T20:21:57.634620Z",
     "shell.execute_reply.started": "2026-01-28T20:21:54.541152Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "USER: Hello! How are you?\n",
      "============================================================\n",
      "\n",
      "AGENT RESPONSE:\n",
      "<final>\n",
      "Hello! I'm good, thanks for asking. How can I help you manage your tasks today?\n",
      "</final>\n",
      "\n",
      "DIRECT RESPONSE: Hello! I'm good, thanks for asking. How can I help you manage your tasks today?\n"
     ]
    }
   ],
   "source": [
    "# Test 5: Conversation\n",
    "test_query(\"Hello! How are you?\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9291919,
     "sourceId": 14548138,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
